for_vis_net %>%
ggraph(layout='graphopt') +
geom_node_point(aes(color = type, size=round(degrees/20))) +
geom_edge_link(alpha = 0.05) +
theme_void() +
ggtitle("Network of New Zealand organisations")
#Считаем базовые параметры графа
# Density
# The proportion of present edges from all possible ties.
p <- edge_density(net)
# связность сети
no <- igraph::components(net)$no # в пакете statnet такое же название
csize <- igraph::components(net)$csize
csize
# Diameter (longest geodesic distance) (если несколько компонент, то диаметр самой большой)
# Note that edge weights are used by default, unless set to NA.
diam <- diameter(net, weights=NA)
diam_w <- diameter(net)
path <- get_diameter(net, weights=NA)
path_w <- get_diameter(net)
path
path_w
# рассчитаем кратчайшие пути
# Average path length
# The mean of the shortest distance between each pair of nodes in the network
# (in both directions for directed graphs).
m_dist <- mean_distance(net, weights=NA)
m_dist_w <- mean_distance(net)
# We can also easily identify the immediate neighbors of a vertex.
# The 'neighbors' function finds all nodes one step out from the focal actor.
# To find the neighbors for multiple nodes, use 'adjacent_vertices()'.
d <- data.frame(neighbors(net, V(net)["University of Auckland"], mode="total")$type)
groups <- as.data.frame(table(d))[, 2]
pie(groups, labels=paste0(as.data.frame(table(d))[, 1], ', ',round(groups/sum(groups)*100, digits=1), '%'),
col=c(5, 2, 3, 4), main='Neighbors of University of Auckland')
# To find node neighborhoods going more than one step out, use function 'ego()'
# with parameter 'order' set to the number of steps out to go from the focal node(s).
neigh2 <- data.frame(ego(net, order = 2, nodes = V(net)["University of Auckland"])[[1]]$type)
groups2 <- as.data.frame(table(neigh2))[, 2]
pie(groups2, labels=paste0(as.data.frame(table(neigh2))[, 1], ', ',round(groups2/sum(groups2)*100, digits=1), '%'),
col=c(5, 2, 3, 4), main='Two-step neighbors of University of Auckland')
#Генерируем модели случайного графа erdos.renyi
p <- edge_density(net)
random_model <- erdos.renyi.game(n=gorder(net), p.or.m=p, type='gnp')
par(mfrow = c(1, 2))
hist(degree(net), main = "Histogram of node degree", breaks = 1:vcount(net)-1, prob = TRUE, xlim=range(c(0, 20)))
hist(degree(random_model), main = "Histogram of node degree", breaks = 1:vcount(net)-1, prob = TRUE, xlim=range(c(0, 20)))
par(mfrow = c(1, 1))
gl <- vector('list', 100)
m <- rep(NA, 100)
d <- rep(NA, 100)
a <- rep(NA, 100)
for (i in 1:100){
gl[[i]] <- erdos.renyi.game(n=gorder(net), p.or.m=p, type='gnp')
m[i] <- mean_distance(gl[[i]])
d[i] <- diameter(gl[[i]])
a[i] <- igraph::components(gl[[i]])$no
}
mean_distance <- m
hist(mean_distance, xlim=range(c(min(m, mean_distance(net)), max(m, mean_distance(net)))))
abline(v=mean_distance(net), col='red', lty=3, lwd=2)
diameter <- d
hist(diameter, xlim=range(c(min(d, diameter(net, weights=NA)), max(d, diameter(net, weights=NA)))))
abline(v=diameter(net, weights=NA), col='red', lty=3, lwd=2)
number_of_components <- a
hist(number_of_components, xlim=range(c(0, 25)))
abline(v=igraph::components(net)$no, col='red', lty=3, lwd=2)
#Генерируем модели случайного графа с регулярной решеткой
n_of_nei <- mean(degree(net))
diam_net <- diameter(net, weights=NA)
#Ищем оптимальное значение p
mean_dist_net <- mean_distance(net)
model <- vector('list', 100)
m <- rep(NA, 100)
d <- rep(NA, 100)
res <- rep(NA, 100)
for (i in 1:100){
model[[i]] <- sample_smallworld(dim = 1, size = gorder(net), nei = n_of_nei, p = i/100)
m[i] <- mean_distance(model[[i]])
d[i] <- diameter(model[[i]])
res[i] <- ((m[i]-mean_dist_net)^2+(d[i]-diam_net)^2)^(1/2)
}
# p = 0.99
random_model <- sample_smallworld(dim = 1, size = gorder(net), nei = n_of_nei, p = 0.99)
par(mfrow = c(1, 2))
hist(degree(net), main = "Histogram of node degree", breaks = 1:vcount(net)-1, prob = TRUE, xlim=range(c(0, 30)))
hist(degree(random_model), main = "Histogram of node degree", breaks = 1:vcount(net)-1, prob = TRUE, xlim=range(c(0, 30)))
par(mfrow = c(1, 1))
gl <- vector('list', 100)
m <- rep(NA, 100)
d <- rep(NA, 100)
a <- rep(NA, 100)
for (i in 1:100){
gl[[i]] <- sample_smallworld(dim = 1, size = gorder(net), nei = n_of_nei, p = 0.99)
m[i] <- mean_distance(gl[[i]])
d[i] <- diameter(gl[[i]])
a[i] <- igraph::components(gl[[i]])$no
}
mean_distance <- m
hist(mean_distance, xlim=range(c(min(m, mean_distance(net)), max(m, mean_distance(net)))))
abline(v=mean_distance(net), col='red', lty=3, lwd=2)
diameter <- d
hist(diameter, xlim=range(c(min(d, diameter(net, weights=NA)), max(d, diameter(net, weights=NA)))))
abline(v=diameter(net, weights=NA), col='red', lty=3, lwd=2)
number_of_components <- a
hist(number_of_components, xlim=range(c(0, 25)))
abline(v=igraph::components(net)$no, col='red', lty=3, lwd=2)
# Генерируем модель Барабаши-Альберта
#Ищем оптимальное значение power
model <- vector('list', 100)
res <- rep(NA, 40)
m <- rep(NA, 100)
d <- rep(NA, 100)
for (i in c(1:40)){
model[[i]] <- sample_pa(n = gorder(net), power = i/10, directed = FALSE)
m[i] <- mean_distance(model[[i]])
d[i] <- diameter(model[[i]])
res[i] <- ((m[i]-mean_dist_net)^2+(d[i]-diam_net)^2)^(1/2)
}
plot(x=c(1:40)/10, y=res)
#power=2.15
random_model <- sample_pa(n = gorder(net), power = 2.15, directed = FALSE)
par(mfrow = c(1, 2))
hist(degree(net), main = "Histogram of node degree", breaks = 1:vcount(net)-1, prob = TRUE, xlim=range(c(0, 20)))
hist(degree(random_model), main = "Histogram of node degree", breaks = 1:vcount(net)-1, prob = TRUE, xlim=range(c(0, 20)))
par(mfrow = c(1, 1))
gl <- vector('list', 100)
m <- rep(NA, 100)
d <- rep(NA, 100)
a <- rep(NA, 100)
for (i in 1:100){
gl[[i]] <- sample_pa(n = gorder(net), power = 2.15, directed = FALSE)
m[i] <- mean_distance(gl[[i]])
d[i] <- diameter(gl[[i]])
a[i] <- igraph::components(gl[[i]])$no
}
mean_distance <- m
hist(mean_distance, xlim=range(c(min(m, mean_distance(net)), max(m, mean_distance(net)))))
abline(v=mean_distance(net), col='red', lty=3, lwd=2)
diameter <- d
hist(diameter, xlim=range(c(min(d, diameter(net, weights=NA)), max(d, diameter(net, weights=NA)))))
abline(v=diameter(net, weights=NA), col='red', lty=3, lwd=2)
number_of_components <- a
hist(number_of_components, xlim=range(c(0, 25)))
abline(v=igraph::components(net)$no, col='red', lty=3, lwd=2)
# Генерируем модель Барабаши-Альберта
#Ищем оптимальное значение power
model <- vector('list', 100)
res <- rep(NA, 40)
m <- rep(NA, 100)
d <- rep(NA, 100)
for (i in c(1:40)){
model[[i]] <- sample_pa(n = gorder(net), power = i/10, directed = FALSE)
m[i] <- mean_distance(model[[i]])
d[i] <- diameter(model[[i]])
res[i] <- ((m[i]-mean_dist_net)^2+(d[i]-diam_net)^2)^(1/2)
}
#power=2.15
random_model <- sample_pa(n = gorder(net), power = 2.15, directed = FALSE)
par(mfrow = c(1, 2))
hist(degree(net), main = "Histogram of node degree", breaks = 1:vcount(net)-1, prob = TRUE, xlim=range(c(0, 20)))
hist(degree(random_model), main = "Histogram of node degree", breaks = 1:vcount(net)-1, prob = TRUE, xlim=range(c(0, 20)))
par(mfrow = c(1, 1))
gl <- vector('list', 100)
m <- rep(NA, 100)
d <- rep(NA, 100)
a <- rep(NA, 100)
for (i in 1:100){
gl[[i]] <- sample_pa(n = gorder(net), power = 2.15, directed = FALSE)
m[i] <- mean_distance(gl[[i]])
d[i] <- diameter(gl[[i]])
a[i] <- igraph::components(gl[[i]])$no
}
mean_distance <- m
hist(mean_distance, xlim=range(c(min(m, mean_distance(net)), max(m, mean_distance(net)))))
abline(v=mean_distance(net), col='red', lty=3, lwd=2)
diameter <- d
hist(diameter, xlim=range(c(min(d, diameter(net, weights=NA)), max(d, diameter(net, weights=NA)))))
abline(v=diameter(net, weights=NA), col='red', lty=3, lwd=2)
number_of_components <- a
hist(number_of_components, xlim=range(c(0, 25)))
abline(v=igraph::components(net)$no, col='red', lty=3, lwd=2)
deg <- degree(net)
# plot(net, vertex.label=NA, layout=layout_with_fr, vertex.size=deg)
# гистограмма степеней вершин
hist(deg, main="Histogram of node degree", breaks=50, prob=TRUE)
# распределение степеней вершин
mean(deg) # Средняя степень вершины по графу
# ~ 5.66
Mode(deg) # Модальная степень вершин графа
# 1 -> 599 раз
median(deg) # Медиана степеней вершин
# ~ 2
top_10_degree <- tail(sort(deg), 10) # топ-10 по степеням
top_10_degree # в топе - 7 университетов, 3 гос. учреждения
clos1 <- closeness(net, weights=NA) # Первый способ - без учета весов
clos1
plot(net, vertex.label=NA, layout=layout_with_fr, vertex.size=clos1 * 50)
top_10_clos1 <- tail(sort(clos1), 10)
# Вектор-топ 42 также будет единичным, а вот вектор-топ 43 уже нет
top_10_clos1
bottom_10_clos1 <- head(sort(clos1), 10)
bottom_10_clos1
clos1["University of Auckland"]
clos2 <- closeness(net)
clos2
plot(net, vertex.label=NA, layout=layout_with_fr, vertex.size=clos2 * 50)
top_10_clos2 <- tail(sort(clos2), 10)
top_10_clos2
bottom_10_clos2 <- head(sort(clos2), 10)
bottom_10_clos2
clos2["University of Auckland"]
betw1 <- betweenness(net, weights=NA)
head(betw1)
top_10_betw1 <- tail(sort(betw1), 10)
top_10_betw1
bottom_10_betw1 <- head(sort(betw1), 10)
bottom_10_betw1
betw1["University of Auckland"]
betw2 <- betweenness(net)
head(betw2)
top_10_betw2 <- tail(sort(betw2), 10)
top_10_betw2
bottom_10_betw2 <- head(sort(betw2), 10)
bottom_10_betw2
betw2["University of Auckland"]
eig1 <- eigen_centrality(net, weights = NA)
head(eig1)
top_10_eig1 <- tail(sort(eig1$vector), 10)
top_10_eig1
bottom_10_eig1 <- head(sort(eig1$vector), 10)
bottom_10_eig1
eig2 <- eigen_centrality(net)
head(eig2)
top_10_eig2 <- tail(sort(eig2$vector),10)
top_10_eig2
bottom_10_eig2 <- head(sort(eig2$vector),10)
bottom_10_eig2
# объединим все центральности в один датафрейм и посмотрим корреляции в двух вариантах
df1 <- data.frame(deg, clos1, betw1, eig1$vector)
cor(df1)
df2 <- data.frame(deg, clos2, betw2, eig2$vector)
cor(df2)
corr1 <- data.frame(
names(top_10_degree),
names(top_10_betw1),
names(top_10_eig1)
)
corr1
corr2 <- data.frame(
names(top_10_degree),
names(top_10_betw2),
names(top_10_eig2)
)
corr2
# Возникли проблемы с вычислением ассортативности через
# assortativity_nominal(net, types=V(net)$type, directed=F)
# Предупреждение: в результате преобразования созданы NA
# [1] NaN
assortativity_nominal(net, types=V(net)$type, directed=F)
# Поэтому было принято решение создать новый столбец с закодированными строками
V(net)$num_type <- ifelse( V(net)$type=="Business Enterprise", 1,
ifelse( V(net)$type=="Private not for profit", 2,
ifelse( V(net)$type=="Government", 3,
ifelse( V(net)$type=="Higher Education", 4, 0)
)
)
)
assort_nom <- assortativity_nominal(net, types=V(net)$num_type, directed=F)
assort_nom # -0.05876298
# значение ассортативности не зависит от конкретных чисел
V(net)$num_type1 <- ifelse( V(net)$type=="Business Enterprise", 2,
ifelse( V(net)$type=="Private not for profit", 7,
ifelse( V(net)$type=="Government", 5,
ifelse( V(net)$type=="Higher Education", 10, 0)
)
)
)
assortativity_nominal(net, types=V(net)$num_type1, directed=F) # -0.05876298
# считаем ассортативность по степени вершины
assort_deg <- assortativity_degree(net, directed=F) # -0.3361749
assort_deg
p <- edge_density(net)
p # 0.003745601
n_c <- sum( V(net)$type == 'Higher Education' )
n_c # 54
exp_diad_uni <- n_c * (n_c - 1) / 2 * p
exp_diad_uni # 5.359955
unis <- V(net)[which( V(net)$type == 'Higher Education' )]
unis <- names(unis)
# unis
m_c <- 0
for (row in 1:nrow(edges)) {
from_obj <- edges[row, 'from']
to_obj <- edges[row, 'to']
if ( (from_obj %in% unis) && (to_obj %in% unis) ) {
m_c <- m_c + 1
}
}
m_c # 172
diadicity_uni <- m_c / exp_diad_uni
diadicity_uni # 32.08982
# 2-й способ посчитать dyadicity
uni_net <- induced_subgraph(
net,
v=V(net)[which( V(net)$type == 'Higher Education' )]
)
# uni_net
# V(uni_net)$type # проверяем, что все вершины в новом графе вузы
edge_density(net) # 0.003745601
edge_density(uni_net) # 0.1201957
edge_density(uni_net) / edge_density(net) # 32.08982
n_c # 54
p # 0.003745601
n_nc <- sum( V(net)$type != 'Higher Education' )
n_nc # 1457
exp_hetero_uni <- n_nc * n_c * p
exp_hetero_uni # 294.6964
m_mixed <- 0
for (row in 1:nrow(edges)) {
from_obj <- edges[row, 'from']
to_obj <- edges[row, 'to']
if ( (from_obj %in% unis) && !(to_obj %in% unis) ) {
m_mixed <- m_mixed + 1
}
if ( !(from_obj %in% unis) && (to_obj %in% unis) ) {
m_mixed <- m_mixed + 1
}
}
m_mixed # 2051
heterophilicity_uni <- m_mixed / exp_hetero_uni
heterophilicity_uni # 6.959706
# uni_biz_net <- induced_subgraph(
#   net,
#   v=V(net)[which(
#     (V(net)$type == 'Higher Education') || (V(net)$type == 'Business Enterprise')
#       )]
# )
uni_biz_net <- induced_subgraph(
net,
v=V(net)[which( V(net)$type %in% c('Higher Education', 'Business Enterprise') )]
)
# uni_biz_net
# V(uni_biz_net)$type
uni_wout_biz_net <- induced_subgraph(
uni_biz_net,
v=V(uni_biz_net)[which( V(uni_biz_net)$type == 'Higher Education' )]
)
# uni_wout_biz_net
# V(uni_wout_biz_net)$type
p_uni_vs_biz <- edge_density(uni_biz_net)
p_uni_vs_biz # 0.003036165
edge_density(uni_wout_biz_net) # 0.1201957
dyadicity_uni_vs_biz <- edge_density(uni_wout_biz_net) / p_uni_vs_biz
dyadicity_uni_vs_biz # 39.58799
n_c # 54
p_uni_vs_biz # 0.003036165
n_nc_biz <- sum( V(net)$type == 'Business Enterprise' )
n_nc_biz # 1010
exp_hetero_uni_vs_biz <- n_nc_biz * n_c * p_uni_vs_biz
exp_hetero_uni_vs_biz # 165.5925
biz <- V(net)[which( V(net)$type == 'Business Enterprise' )]
biz <- names(biz)
# biz
m_mixed_vs_biz <- 0
for (row in 1:nrow(edges)) {
from_obj <- edges[row, 'from']
to_obj <- edges[row, 'to']
if ( (from_obj %in% unis) && (to_obj %in% biz) ) {
m_mixed_vs_biz <- m_mixed_vs_biz + 1
}
if ( (from_obj %in% biz) && (to_obj %in% unis) ) {
m_mixed_vs_biz <- m_mixed_vs_biz + 1
}
}
m_mixed_vs_biz # 1139
heterophilicity_uni_vs_biz <- m_mixed_vs_biz / exp_hetero_uni_vs_biz
heterophilicity_uni_vs_biz # 6.878333
uni_gov_net <- induced_subgraph(
net,
v=V(net)[which( V(net)$type %in% c('Higher Education', 'Government') )]
)
# V(uni_gov_net)$type
uni_wout_gov_net <- induced_subgraph(
uni_gov_net,
v=V(uni_gov_net)[which( V(uni_gov_net)$type == 'Higher Education' )]
)
# V(uni_wout_gov_net)$type
p_uni_vs_gov <- edge_density(uni_gov_net)
p_uni_vs_gov # 0.04231381
edge_density(uni_wout_gov_net) # 0.1201957
dyadicity_uni_vs_gov <- edge_density(uni_wout_gov_net) / p_uni_vs_gov
dyadicity_uni_vs_gov # 2.840578
n_c # 54
p_uni_vs_gov # 0.04231381
n_nc_gov <- sum( V(net)$type == 'Business Enterprise' )
n_nc_gov # 1010
exp_hetero_uni_vs_gov <- n_nc_gov * n_c * p_uni_vs_gov
exp_hetero_uni_vs_gov # 2307.795
gov <- V(net)[which( V(net)$type == 'Business Enterprise' )]
gov <- names(gov)
# gov
m_mixed_vs_gov <- 0
for (row in 1:nrow(edges)) {
from_obj <- edges[row, 'from']
to_obj <- edges[row, 'to']
if ( (from_obj %in% unis) && (to_obj %in% gov) ) {
m_mixed_vs_gov <- m_mixed_vs_gov + 1
}
if ( (from_obj %in% gov) && (to_obj %in% unis) ) {
m_mixed_vs_gov <- m_mixed_vs_gov + 1
}
}
m_mixed_vs_gov # 0.4935447
heterophilicity_uni_vs_gov <- m_mixed_vs_gov / exp_hetero_uni_vs_gov
heterophilicity_uni_vs_gov # 0.4935447
# проводим кластеризацию при помощи метода Edge-betweenness
ceb <- cluster_edge_betweenness(net, weights=E(net)$weight)
# смотрим на полученные в результате кластеризации объекты
mbship_ceb <- membership(ceb)
# mbship_ceb
s_ceb <- sizes(ceb)
s_ceb
ms_ceb <- modularity(ceb)
ms_ceb # 0.527262
# ceb
# > s_ceb <- sizes(ceb)
# > s_ceb
# Community sizes
#   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20
#  45 213 233 154 229 190  75  46 164  48  32   2   2   2   3  15   2   2   8   2
#  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38
#   2   4   2   2   2   2   7   2   2   2   2   2   2   2   2   2   3   2
# > ms_ceb <- modularity(ceb)
# > ms_ceb
# [1] 0.527262
plot(
ceb, net,
vertex.label=NA,
vertex.color=V(net)$color,
layout=layout_nicely
)
plot(
ceb, net,
vertex.label=NA,
vertex.color=V(net)$color,
layout=layout_with_lgl
)
compare(ceb, V(net)$type, method='nmi') #
# здесь и далее мы используем нормализованное значение функции compare() для облегчения интерпретации возвращаемого результата
# проводим кластеризацию при помощи метода Fast-greedy
cfg <- cluster_fast_greedy(net, weights=E(net)$weight)
# смотрим на полученные в результате кластеризации объекты
mbship_cfg <- membership(cfg)
# mbship_cfg
s_cfg <- sizes(cfg)
s_cfg
ms_cfg <- modularity(cfg)
ms_cfg # 0.5310055
# cfg
# > s_cfg <- sizes(cfg)
# > s_cfg
# Community sizes
#   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26
# 219 144 212 132 141  94 189 120  84  82  28   3   2  15   3   3   2   2   2   2   2   2   2   2   2   2
#  27  28  29  30  31  32  33  34  35  36
#   2   2   2   2   2   2   2   2   2   2
# > ms_cfg <- modularity(cfg)
# > ms_cfg
# [1] 0.5310055
plot(
cfg, net,
vertex.label=NA,
vertex.color=V(net)$color,
layout=layout_nicely
)
plot(
cfg, net,
vertex.label=NA,
vertex.color=V(net)$color,
layout=layout_with_lgl
)
compare(cfg, V(net)$type, method='nmi') # 0.03386511
res <- rep(NA, 20)
pr <- rep(NA, 20)
for (j in 1:20){
network <- net
V(network)[which( V(network)$type == 'Higher Education' )]$type = 1
V(network)[which(V(network)$type != 1)]$type = 0
# вероятность вершины перейти в класс churn = 1 равна доле соседей churn = 1 от общего числа соседей
# используем матричные вычисления
random_uni <- sample( V(network)[ which(V(network)$type == 1) ], 10 )
random_not_uni <- sample( V(network)[ which(V(network)$type == 0) ], 10 )
for (i in 1:1511){
if (!(V(network)[i] %in% random_uni | (V(network)[i] %in% random_not_uni))){
V(network)$type[i] = 0.5
}
}
UniProb <-  as.numeric(V(network)$type)
threshold <- 0.5
A <- as_adjacency_matrix(network)
A <- as.matrix(A)
Neighbors <- rowSums(A) # общее число соседей вершины
UniProb_iter <- UniProb
for(i in 1:10){
UniProb_iter <- as.vector((A %*% UniProb_iter) / Neighbors)
}
res[j] <- length(which(UniProb_iter > threshold))
pr[j] <- mean(UniProb_iter)
}
hist(res, main='Число предсказанных университетов')
hist(pr, main='Средняя вероятность принадлежности классу 1')
