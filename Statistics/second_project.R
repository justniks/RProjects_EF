# насколько я понял, нужно каждый раз заново говорить RStudio, в какой 
# директории мы работаем

### Загружаем датасет
D <- read.csv("males.csv", sep=";")
D

D_1980 <- D[D$YEAR==1980, ]
D_1980
D_1987 <- D[D$YEAR==1987, ]
D_1987


############### Протестируем одну выборку
### Проверим гипотезу, что половина мужчин женаты

# binom.test(x, n, p = 0.5,
#            alternative = c("two.sided", "less", "greater"),
#            conf.level = 0.95)

  # x	-- number of successes, or a vector of length 2 giving the numbers of successes and failures, respectively.
  
  # n	-- number of trials; ignored if x has length 2.
  
  # p	-- hypothesized probability of success.
  
  # binom.test() -> предполагаем, что датасет распределен по Бернульке

x_binom <- sum(D_1980$MAR) # число успехов
n <- length(D_1980$MAR) # это кол-во "испытаний"
binom.test(x_binom, n, 0.5)
# отсюда мы понимаем, что истинная вероятность, скорее всего, != 0.5
# на любом уровне значимости > p-value мы отвергаем нулевую гипотезу (0.5)



### H_0: среднее отработанное число часов соответсвует 4-часовой рабочей неделе
# t.test() -> этот тест только для мат. ожидания 
# (можем проверять гипотезы, считать оценки, ДИ но только для м.о. и для 
# нормальных данных)

# ! предполагаем нормальность данных
a <- 52 * 40
x_t_test <- D_1980$HOURS
t.test(x_t_test, mu=a)
# t = -4.6519, df = 544, p-value = 4.135e-06
# т.е. он сам посчитал число степеней свободы

# отвергаем нулевую гипотезу


### H_0: Standard deviation = 10% от среднего
install.packages('EnvStats')
library(EnvStats)

d <- ( mean(D_1980$WAGE) * 0.1 )^2 #  если бы мы считали standard devation, то 
# квадрат бы не писали

  # фиксим трабл с числами в текстовом формате:
  # D_1980$WAGE <- as.numeric(D_1980$WAGE)

# только для нормальных данных
varTest(D_1980$WAGE, sigma.squared = d)
# p-value = 0 => всегда отвергаем нулевую гипотезу


############### Протестируем две выборки
### H_0: доля жителей сельской местности не изм-сь с 1980 по 1987 год
m1 <- sum(D_1980$RUR) # потому что Бернулька
m2 <- sum(D_1987$RUR)

m <- c(m1, m2)
n <- c(n , n)

# по сути это t.test для Бернулек
prop.test(m, n) # параметры -- число успехов и число испытаний
# не можем отвергнуть эту гипотезу
# ДИ тут для разности между сл. вел.


### H_0: з/п не изменилась за период 1980-1987
t.test(D_1980$WAGE, D_1987$WAGE) # тут по умолч. предполагается, что дисперсии разные
# Welch Two Sample t-test -> модификация t.test для неизвестных неравных дисперсий

# вообще сначала надо проверить, равны ли дисперсии
var.test(D_1980$WAGE, D_1987$WAGE)
# маленькое p-value => дисперсии не равны, т.е. тест выше ОК

## посмотрим, что произойдет, если мы зададим равенство дисперсий:
t.test(D_1980$WAGE, D_1987$WAGE, var.equal=TRUE)
# можно считать, что дисперсии разные



################## Критерии согласия
### chisq.test(x) -> нужно подготовить данные (разберем в среду)

shapiro.test(D_1980$WAGE) # просто подставляем данные
# маленькое p-value => отвергаем гипотезу о нормальности
shapiro.test(D_1980$AGE) # для нормальности


### Kolmogorov-Smirnov test
ks.test(D_1980$WAGE, D_1987$WAGE) # сравнение распределений двух выборок
# отвергаем


### ks.test for normality
ks.test(D_1980$WAGE, "pnorm") # просто подставляем название распределения, 
# с к-рым хотим сравнить
# маленькое p-value => отвергаем нормальность

ks.test(D_1980$WAGE, "pt", df=2) # Стьюдент
